\documentclass[11pt]{article}
\usepackage{cs267}

%%%%%%%%%%%%%%%%%%%% name/id
\rfoot{\small Brian Park | 3033045069}


%%%%%%%%%%%%%%%%%%%% Course/HW info
\newcommand*{\instr}{Aydın Buluç and Jim Demmel}
\newcommand*{\term}{Spring 2022}
\newcommand*{\coursenum}{CS 267}
\newcommand*{\coursename}{Applications of Parallel Computers}
\newcommand*{\hwnum}{0 Pre-proposal}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Document Start %%%%%%%%%%%%%%%%%
\begin{document}

My name is Brian Park and I am an undergraduate Computer Science major who will be graduating this semester. I also do research in the RISELab on the NumS project, an open source library that extends NumPy to distributed systems using Ray. It also provides distributed model training. My interests lie deeply in computer architecture, systems, and machine learning. I'm passionate about finding ways we can accelerate machine learning as well as make it efficient. What I want to get out of this class is learn other parallel programming tools, such as CUDA, MPI, and UPC++.

A problem in machine learning is that training time takes a long time, especially on the CPU. Vendors are making specialized hardware to accelerate machine learning workloads, such as utilizing GPUs, TPUs, and other kinds of neural accelerators. Memory seems to be the most expensive operation, as you iterate over a lot of data. Industry has found a way to mitigate this change by using lower precision floating point number, such as 16 bit half precision numbers. This tradeoff seems to be feasible, as machine learning doesn't need to care a lot about accuracy as long as it provides good enough prediction. Also, you can obtain more FLOPS in performance, since 16 bit numbers can pack more tightly into memory and on to SIMD vectors. For example, using 512 bit intrinsics, we are able to fit 8 doubles. With 16 bit floating point, we can pack 32 half precision numbers.




Examine an application problem for which parallel computing has been used. You may pick a problem from your own research area, somewhere on the web, or elsewhere (so long as it is verifiable). Briefly describe the application, the use of parallelism, and a frank assessment of its success, weaknesses, and challenges.

Some specific details to consider include the following:

What is the scientific or engineering problem being solved?

How well did the application achieve its scientific/engineering objective? Are simulation results compared to physical results?

What parallel platform has the application targeted? (distributed vs. shared memory, vector, etc.) What tools were used to build the application? (languages, libraries, etc.)

If the application is run on a major supercomputer, where does that computer rank on the Top 500 list?

How well did the application perform? How does this compare to the platform's best possible performance?

Does the application "scale" to large problems on many processors? If you believe it has not, what bottlenecks may have limited its performance?

Not all of these details will be available for all applications. You ought to explain what you find noteworthy about the application or its implementation.


\end{document}


